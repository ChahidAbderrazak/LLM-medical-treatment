{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kS8xG6uHq0ZQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "IN_COLAB = False if os.getenv(\"COLAB_RELEASE_TAG\") is None else True\n",
    "print(IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWLO4-GLq0ZR"
   },
   "source": [
    "##### Copy project to Colab Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D1LT_OFs0Sk3"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    project_root = \"/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis\"\n",
    "    data_folder = \"/content/drive/MyDrive/dataset/LLM/sentiment140\"  # os.path.join(project_root, \"data\")\n",
    "    INPUT_FILE_COLAB = \"data/training.1600000.processed.noemoticon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CVC2caur0Pw0"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    ## --------Mount google drive to Colab --------\n",
    "    import os\n",
    "    import sys\n",
    "    from google.colab import drive\n",
    "\n",
    "    root = \"/content\"\n",
    "    drive.mount(os.path.join(root, \"drive/\"), force_remount=True)\n",
    "\n",
    "    # -------- copy the project code and data----------------\n",
    "    project_tag = (\n",
    "        os.path.basename(os.path.dirname(project_root))\n",
    "        + \"_\"\n",
    "        + os.path.basename(project_root)\n",
    "    )\n",
    "    project_tag\n",
    "    %cd $root\n",
    "    %rm -rfv project\n",
    "\n",
    "    # import the project code to workspace\n",
    "    import os\n",
    "\n",
    "    %cd $root\n",
    "    %rm -rfv project\n",
    "    %mkdir project\n",
    "    !cp -r $project_root/* project\n",
    "    %cd project\n",
    "\n",
    "    #  copy the project data locally\n",
    "    !rm  -r data/\n",
    "    !cp  -r \"$data_folder/\" data/\n",
    "    !ls data\n",
    "\n",
    "    # extract the zip data\n",
    "    !unzip data/*.zip -d data/\n",
    "    !unzip data/*/*.zip -d data/*/\n",
    "\n",
    "    # show the copied data\n",
    "    %ls data/**/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHtKY3gy0Zxl"
   },
   "source": [
    "#### input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v79255080OTG"
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = \"artifacts/data_ingestion/training.1600000.processed.noemoticon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rPA3pklSq0ZY"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    INPUT_FILE = INPUT_FILE_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "180f0dd2a95419e4602b5c0229822b0111c826f6",
    "id": "P3p27ui60OTV"
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC\n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"models/model.keras\"\n",
    "WORD2VEC_MODEL = \"models/model.w2v\"\n",
    "TOKENIZER_MODEL = \"models/tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"models/encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup the workspace variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mUC1LA410OTN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "%cd /app\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9mlfRn1CRd9X"
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92b885dd147dac19bd0a33db3cd0da100bd5bc23",
    "id": "IpdllG5T0OTP"
   },
   "source": [
    "#### install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "70282bce8b42a51e4d44f2c7d85c4ca9567b0fd4",
    "id": "sBh12fFJ0OTR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gensim==4.3.3 in /usr/local/lib/python3.8/site-packages (4.3.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.8/site-packages (from gensim==4.3.3) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/site-packages (from gensim==4.3.3) (7.0.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.8/site-packages (from gensim==4.3.3) (1.24.3)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim==4.3.3) (1.17.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 2.14.0 Requires-Python >=3.9; 2.14.0rc0 Requires-Python >=3.9; 3.0.0 Requires-Python >=3.9; 3.0.1 Requires-Python >=3.9; 3.0.2 Requires-Python >=3.9; 3.0.3 Requires-Python >=3.9; 3.0.4 Requires-Python >=3.9; 3.0.5 Requires-Python >=3.9; 3.1.0 Requires-Python >=3.9; 3.1.1 Requires-Python >=3.9; 3.2.0 Requires-Python >=3.9; 3.2.1 Requires-Python >=3.9; 3.3.0 Requires-Python >=3.9; 3.3.1 Requires-Python >=3.9; 3.3.2 Requires-Python >=3.9; 3.3.3 Requires-Python >=3.9; 3.4.0 Requires-Python >=3.9; 3.4.1 Requires-Python >=3.9; 3.5.0 Requires-Python >=3.9; 3.6.0 Requires-Python >=3.9; 3.7.0 Requires-Python >=3.9\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement keras==3.7.0 (from versions: 0.2.0, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.0.7, 1.0.8, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.2.1, 1.2.2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.6, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.5.0rc0, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0rc3, 2.6.0, 2.7.0rc0, 2.7.0rc2, 2.7.0, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.10.0rc0, 2.10.0rc1, 2.10.0, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0rc3, 2.11.0, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.1rc0, 2.13.1rc1, 2.13.1, 2.15.0rc0, 2.15.0rc1, 2.15.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for keras==3.7.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 2.1.0 Requires-Python >=3.9; 2.1.0rc0 Requires-Python >=3.9; 2.1.1 Requires-Python >=3.9; 2.1.2 Requires-Python >=3.9; 2.1.3 Requires-Python >=3.9; 2.1.4 Requires-Python >=3.9; 2.2.0 Requires-Python >=3.9; 2.2.0rc0 Requires-Python >=3.9; 2.2.1 Requires-Python >=3.9; 2.2.2 Requires-Python >=3.9; 2.2.3 Requires-Python >=3.9\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pandas==2.2.3 (from versions: 0.1, 0.2, 0.3.0, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.5.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.8.0, 0.8.1, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.21.0, 0.21.1, 0.22.0, 0.23.0, 0.23.1, 0.23.2, 0.23.3, 0.23.4, 0.24.0, 0.24.1, 0.24.2, 0.25.0, 0.25.1, 0.25.2, 0.25.3, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.4.0rc0, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.5.0rc0, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 2.0.0rc0, 2.0.0rc1, 2.0.0, 2.0.1, 2.0.2, 2.0.3)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pandas==2.2.3\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "%pip install gensim==4.3.3 #--upgrade\n",
    "%pip install keras==3.7.0 #--upgrade\n",
    "%pip install pandas==2.2.3 #--upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWIsgkThvmgh"
   },
   "source": [
    "# Project: Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yHdOMw4u_fc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### load the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "303e72966af732ddef0bd8108a321095314e44af",
    "id": "yHdrhJ0-0OTS"
   },
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    LSTM,\n",
    ")\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35e1a89dead5fd160e4c9a024a21d2e569fc89ff",
    "id": "8dASwPxJ0OTT"
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c3beecc618be68480b3d4f0de08d9d863da1dc1",
    "id": "7yF6T9xF0OTW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "563b3c44f1092dba0b853747b098e00509098cca",
    "id": "_YLedtL10OTW"
   },
   "source": [
    "### Loaded dataset\n",
    "The loaded datset schema is :\n",
    "* **target**: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "* **ids**: The id of the tweet ( 2087)\n",
    "* **date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* **flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* **user**: the user that tweeted (robotickilldozr)\n",
    "* **text**: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bba8f91cd70de4f5ea0fb0870ae2029b6e3dcc24",
    "id": "vG7CxZb20OTW"
   },
   "outputs": [],
   "source": [
    "print(\"Open file:\", INPUT_FILE)\n",
    "df = pd.read_csv(INPUT_FILE, encoding=DATASET_ENCODING, names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "936d499c00c4f1648bc16ca9d283c3b39be7fb10",
    "id": "aFSEZt5t0OTX"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7486ed895b813c5246f97b31b6162b0f65ff763b",
    "id": "qZGrVBp10OTX"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f9a7bb129e184967b13261fb5d253af451c75c5",
    "id": "daLlzo5I0OTY"
   },
   "source": [
    "### Map target label to String\n",
    "* **0** -> **NEGATIVE**\n",
    "* **2** -> **NEUTRAL**\n",
    "* **4** -> **POSITIVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14074b59106cb9550440839e48b832223fc9502f",
    "id": "FlOt77FN0OTY"
   },
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "\n",
    "\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4449d473187f647a195a6ac6986b009da32a7f4b",
    "id": "vV4iwJcp0OTZ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19eb327803192f31cce3512aacb232f4d6b38715",
    "id": "d6j219KQ0OTZ"
   },
   "outputs": [],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4329b1573518b03e497213efa7676220734ebb4b",
    "id": "hOK9kGAU0OTa",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Cleaning and pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f1b4dWPSYID"
   },
   "source": [
    "### clean unvalid texts (stemmer language -> english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8aeee8b7b9ea11b749c7f91cd4787a7b50ed1a91",
    "id": "edh4YMe-0OTa"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "649ebcb97969b9ac4301138783704bb3d7846a49",
    "id": "RnH9e0jn0OTa"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, \" \", str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7f3e77ab9291d14687c49e71ba9b2b1e3323432",
    "id": "c1QPYQxD0OTb"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5f9714a8507409bbe780eebf2855a33e8e6ba37",
    "id": "KORKJq4T0OTb"
   },
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2b1179c968e3f3910c790ecf0c5b2cbb34b0e68",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXNQ3kfR0OTb",
    "outputId": "1c3a094a-4625-4dcc-f269-22f6afca1f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 1280000\n",
      "TEST size: 320000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1 - TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6NiS0qbwiDR"
   },
   "source": [
    "## Data Transformtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f08a28aab2c3d16d8b9681a7d5d07587153a1cd6",
    "id": "5ixH3C2G0OTc"
   },
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhVbGdeF8FDl"
   },
   "source": [
    "#### prepare the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2461bf564de1b4414841933d0c1d1bee5f5cc5a6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6OjCdND0OTc",
    "outputId": "1b7d3ffa-f565-421d-ebee-98263fc9c29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.46 s, sys: 844 ms, total: 8.3 s\n",
      "Wall time: 8.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e19b9f25801ba86420decc266d2b3e6fb44f1ea",
    "id": "RgM8ECzV0OTc"
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(\n",
    "    vector_size=W2V_SIZE, window=W2V_WINDOW, min_count=W2V_MIN_COUNT, workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMzBvgTRrJiA",
    "outputId": "d815d318-4242-4973-a389-aba8ffd4eff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- the pretrained model was loadded successfully from the path models/model.w2v\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained Word2Vec model if any.\n",
    "if os.path.exists(WORD2VEC_MODEL):\n",
    "    w2v_model = gensim.models.Word2Vec.load(WORD2VEC_MODEL)\n",
    "    print(\n",
    "        f\"- the pretrained model was loadded successfully from the path {WORD2VEC_MODEL}\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"- no pretrained model was found in path {WORD2VEC_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58d655af07653c594bec6bebcfb302a973b0ad9c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "geRvXBy-0OTd",
    "outputId": "181da209-e3af-4cba-c83b-3ce51da86848",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 30459 is out of bounds for axis 0 with size 30369",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e314fe26fd45>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mreport_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mprepare_vocab\u001b[0;34m(self, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_vocab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_by_descending_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msort_by_descending_frequency\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sorting after vectors have been allocated is expensive & error-prone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_sorted_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 30459 is out of bounds for axis 0 with size 30369"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72a5628ca81fd4b8983c12d93ae0bf950b86b6ae",
    "id": "Kl3ebz5i0OTd"
   },
   "outputs": [],
   "source": [
    "words = list(w2v_model.wv.index_to_key)\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X3vlcrI7_KK"
   },
   "source": [
    "#### train the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68c3e4a5ba07cac3dee67f78ecdd1404c7f83f14",
    "id": "2y3eRGTl0OTe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)\n",
    "\n",
    "# save the trained w2v_model\n",
    "w2v_model.save(WORD2VEC_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27cc2651c74227115d8bfd8c40e5618048e05edd",
    "id": "m9RsIvIC0OTf"
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e13563644468037258598637b49373ca96b9b879",
    "id": "XC2ZkEWc0OTf"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6852bc709a7cd20173cbeeb218505078f8f37c57",
    "id": "3JLCFaHZ0OTf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45de439df3015030c71f84c2d170346936a1d68f",
    "id": "OahPw6ab0OTg"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH\n",
    ")\n",
    "x_test = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03b35903fc6260e190d6928d240ef7432de117fc",
    "id": "fUnbwtmG0OTg"
   },
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33676e0efa39e97d89bd650b8b4eae933a22fbf0",
    "id": "iw5DU5U10OTg"
   },
   "outputs": [],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels.append(NEUTRAL)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04239a9bef76e7922fd86098a5601dfde8ee4665",
    "id": "hoXq2Ew30OTh"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04299c886911ca135583ab64878f213939a2990c",
    "id": "L9YiFfUk0OTh"
   },
   "outputs": [],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "232533fb27b7be99d9b8c2f8fb22c9c6bf121a6f",
    "id": "PdfxwCZG0OTh"
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gMOc5yqwym_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNi7HH50w8Y-"
   },
   "source": [
    "### Build embeddings layer and classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "233c0ea94055a03e2e7df3e2a13d036ec963484f",
    "id": "x9NWd8wd0OTh"
   },
   "source": [
    "#### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ab488374b59e3f30f8b1ea92767d853c4846bac",
    "id": "IoLZ_JpS0OTq"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "833279d91e4286065968237fb5f2a0c2dd4d246c",
    "id": "WpwPJNqK0OTq"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    vocab_size,\n",
    "    W2V_SIZE,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=SEQUENCE_LENGTH,\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b299ef78f94c2085942c993a2d58753a7476305a",
    "id": "jfcPD83T0OTr"
   },
   "source": [
    "#### Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e775ef4f1b74e6412457181383c39f2df554ef3f",
    "id": "Q7SO2ehy0OTr"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSqH6fUwxNfu"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28d22eafd0c7d798dcf3d742bc92fb8577939e6c",
    "id": "Q8c6qQcP0OTr"
   },
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1331e08d590bb2aa2033706c8faca217afc0f1c3",
    "id": "4lPrcNKM0OTs"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7733127cb8b380e0c807268903bf4d03ef92542",
    "id": "wyEDJfyW0OTs"
   },
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a688df590386f5748da6fe00b01904fe6c71619e",
    "id": "xm9pBRhK0OTs"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", patience=5, cooldown=0),\n",
    "    EarlyStopping(monitor=\"val_accuracy\", min_delta=1e-4, mode=\"max\", patience=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d0873633dd49179c8cae17377641b97d323ef3b",
    "id": "6_5VXegg0OTs"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbaMbJPZ7eGz"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained classification model if any.\n",
    "if os.path.exists(KERAS_MODEL):\n",
    "    model = tf.keras.models.load_model(KERAS_MODEL)\n",
    "    print(\n",
    "        f\"- the pretrained model was loadded successfully from the path {WORD2VEC_MODEL}\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"- no pretrained model was found in path {KERAS_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b659d390c6577dc5cdb6b6297934279b4e801d5",
    "id": "ikZT_IbY0OTt"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# history = model.fit(x_train, y_train,\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "#                     epochs=1,\n",
    "#                     validation_split=0.1,\n",
    "#                     verbose=1,\n",
    "#                     callbacks=callbacks)\n",
    "\n",
    "# # save trained model\n",
    "# model.save(KERAS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f014c32f3833db282e1a075c526604f34e3158c",
    "id": "MtgiZhxo0OT1"
   },
   "source": [
    "#### Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeEpwGNM3COQ"
   },
   "outputs": [],
   "source": [
    "%cd $root/project\n",
    "%mkdir  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b2b3ad5b592977b404acfa1c9ad303a62837255",
    "id": "74KUYfRI0OT1"
   },
   "outputs": [],
   "source": [
    "# model.save(KERAS_MODEL)\n",
    "# w2v_model.save(WORD2VEC_MODEL)\n",
    "# pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "# pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "267258196d96796ac69a7b8c466314bcf5d6ee42",
    "id": "6uFGMac20OTt"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TWp1seox0wQ"
   },
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98ecd8f1b8b74594c3ea775dd68a094e92458022",
    "id": "wRp8XB270OTt"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "# print(\"\\nACCURACY:\",score[1])\n",
    "# print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c72cd1e9d6c4fd799cbba7c813765ac4039dfc",
    "id": "HocAW2vi0OTu"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, \"b\", label=\"Training acc\")\n",
    "    plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"\\n - The training performance is not avaialble!!\\\n",
    "  \\n because {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ee72e47f84b6dbc32e02a783de5ec1661f157e1",
    "id": "S207Tv7H0OTx"
   },
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e920173eb05f04aecdd735bc5dff0f5be5f8d15",
    "id": "8eMZ70pv0OTx"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# y_pred_1d = []\n",
    "# y_test_1d = list(df_test.target)\n",
    "# scores = model.predict(x_test, verbose=1, batch_size=8000)\n",
    "# y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3575191bb425ab871f3f41e83812ee84bb7e595",
    "id": "lS-cZgdB0OTy"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title=\"Confusion matrix\", cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = \".2f\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"True label\", fontsize=25)\n",
    "    plt.xlabel(\"Predicted label\", fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a57dc6f6211c144491a70f533225edfa95a2dc66",
    "id": "rmY7H48P0OTy"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e23b957348dcc084249d3cc7538b972da471c2cd",
    "id": "zOthYg-N0OTy"
   },
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7fe05b7caa1c984ff1deb0be2f7c6bc043df9f5",
    "id": "MTvgtTlx0OTz"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4eb300f0c6693a618587c7dcf32f77f5416cbfb9",
    "id": "DjR65y8F0OT0"
   },
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cf76e6e09f8a60ed25947932b94c772eda44d23",
    "id": "AnB8op8x0OT0"
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_test_1d, y_pred_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjUbfTzE2plP"
   },
   "source": [
    "### Export the trained model to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EGatV5Y2u_K",
    "outputId": "74ee7305-2573-430e-be1f-d83715b28ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/project\n",
      "mkdir: invalid option -- 'f'\n",
      "Try 'mkdir --help' for more information.\n",
      "'models/model.h5' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/model.h5'\n",
      "'models/model.w2v' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/model.w2v'\n",
      "'models/tokenizer.pkl' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/tokenizer.pkl'\n",
      "'models/encoder.pkl' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/encoder.pkl'\n",
      "'models/model.keras' -> '/content/drive/MyDrive/Colab-Notebooks/LLM/sentiment-analysis/models/model.keras'\n",
      "^C\n",
      "cp: cannot stat 'artifacts/models': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    %cd $root/project\n",
    "    %mkdir -fp $project_root/models\n",
    "    %cp -rfv models $project_root/\n",
    "    %cp -rfv artifacts/models $project_root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "eXrptWRqq0Zz"
   },
   "outputs": [],
   "source": [
    "# ## Exit colab\n",
    "# if IN_COLAB:\n",
    "# \tfrom google.colab import runtime\n",
    "# \truntime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bdfc0f6a6af5bebc0271d83dd7432c91001409b",
    "id": "9nT3E5pL0OTu"
   },
   "source": [
    "## Model Inference and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensim (/usr/local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %pip install keras==2.3.1\n",
    "%pip install pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr7D6FmA1jRq"
   },
   "source": [
    "#### load the trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlzCz5sf1j-Y",
    "outputId": "d4007693-56de-4450-c678-2ec5ca3f9819"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.legacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load tokenizer from the pickle file\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(TOKENIZER_MODEL, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     loaded_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Test loaded tokenizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.legacy'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load tokenizer from the pickle file\n",
    "with open(TOKENIZER_MODEL, \"rb\") as file:\n",
    "    loaded_tokenizer = pickle.load(file)\n",
    "\n",
    "# Test loaded tokenizer\n",
    "text = \"Hello\"\n",
    "tokenized_text = loaded_tokenizer.texts_to_sequences(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkHap_2P154j",
    "outputId": "0387f577-0375-4c64-9832-8d6c91085ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- example_labels = [0, 1]      \n",
      "- encoded_classes = ['NEGATIVE' 'POSITIVE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer from the pickle file\n",
    "with open(ENCODER_MODEL, \"rb\") as file:\n",
    "    loaded_encoder = pickle.load(file)\n",
    "\n",
    "# Test loaded tokenizer\n",
    "example_labels = [k for k in range(len(loaded_encoder.classes_))]\n",
    "encoded_labels = loaded_encoder.inverse_transform(example_labels)\n",
    "\n",
    "assert set(loaded_encoder.classes_) == set(encoded_labels)\n",
    "print(\n",
    "    f\"- example_labels = {example_labels}\\\n",
    "      \\n- encoded_classes = {encoded_labels}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGTI2X49ykpz"
   },
   "source": [
    "#### load the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "paa77juk0AHb"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec.load(WORD2VEC_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNZpxOko4iLi",
    "outputId": "424e2a9e-2911-4646-f99f-d3138e109a1a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loaded_clf_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mload_model(KERAS_MODEL)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:58\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m---> 58\u001b[0m   module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:961\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:961\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:973\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.api'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loaded_clf_model = tf.keras.models.load_model(KERAS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwv038Ws5TQp"
   },
   "source": [
    "#### prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0b0fa3d4b1bb14b3f5e3d169a369f3ebef29ae1",
    "id": "BLUcHhwF0OTv"
   },
   "outputs": [],
   "source": [
    "# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "# def decode_sentiment(label):\n",
    "#     return decode_map[int(label)]\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:\n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE\n",
    "\n",
    "\n",
    "def show_sentiment_thermometer(label, score):\n",
    "    if score < 0.5:\n",
    "        color = {\"bar_color\": \"#cc0000\"}\n",
    "    elif score == 0.5:\n",
    "        color = {\"bar_color\": \"#555753\"}\n",
    "    else:\n",
    "        color = {\"bar_color\": \"#00ff00\"}\n",
    "\n",
    "    thermometer = widgets.FloatProgress(\n",
    "        value=score,\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        description=label,\n",
    "        bar_style=\"info\",\n",
    "        style=color,\n",
    "        orientation=\"horizontal\",\n",
    "    )\n",
    "\n",
    "    display(thermometer)\n",
    "\n",
    "    return thermometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed4086d651f2f8cbed11d3c909a8873607d29a06",
    "id": "BGA9wrWy0OTv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def predict(text, tokenizer, model, include_neutral=True):\n",
    "\n",
    "    start_at = time.time()\n",
    "    # clean and preprocess the input text\n",
    "    text = (lambda x: preprocess(x))(text)\n",
    "\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    score = np.squeeze(score)\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    # print the predictions\n",
    "    print(f\"\\n- processed text : {text}\")\n",
    "    print(f\"\\n- predicted sentiment : {label} (score={100*score:.1f} %)\")\n",
    "    # show thermometer\n",
    "    show_sentiment_thermometer(label, score)\n",
    "\n",
    "    # get results\n",
    "    result = {\n",
    "        \"label\": label,\n",
    "        \"score\": float(score),\n",
    "        \"elapsed_time\": time.time() - start_at,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRujwlyXyXVe"
   },
   "source": [
    "#### prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca38b1e6c9b5acfed7467de2cf02a78333108872",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "36551f8be8224c77b37e10099b3be61b",
      "5a2a377a20ad4ebdbda152e41f7ecd12",
      "d4aa58ae73f34a01adeb5ec6d3a69555"
     ]
    },
    "id": "CpsR8nXW0OTv",
    "outputId": "77283556-90c6-4de8-b13c-5529af1d5b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "\n",
      "- processed text : love latest roky music\n",
      "\n",
      "- predicted sentiment : POSITIVE (score=98.8 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36551f8be8224c77b37e10099b3be61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.9880579710006714, bar_style='info', description='POSITIVE', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"I love the latest @RoKy music\", loaded_tokenizer, loaded_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e5fe647533be0148850de349fea6ef6f71303d1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "ef45692e7475432aa4a592e5c98b1b81",
      "8748ebdddc2e4b91ad07ba95fa1365b9",
      "a3020eb8cf6a466dba5d09dca1bd4356"
     ]
    },
    "id": "QDT07SdP0OTw",
    "outputId": "8d55b00e-cdac-4df0-f0cc-c93f873b09eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\n",
      "- processed text : hate rain\n",
      "\n",
      "- predicted sentiment : NEGATIVE (score=1.2 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef45692e7475432aa4a592e5c98b1b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.011537362821400166, bar_style='info', description='NEGATIVE', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"I hate the rain\", loaded_tokenizer, loaded_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37064dffcc8920d34ccd54fac7c8b50e583a8269",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "11ed11f99bcf442da88b6915edcdfe84",
      "adcebac5487349ee91fbffeee7b4d942",
      "c31b40d5735440e5bf9bc61daf6fc264"
     ]
    },
    "id": "cOw-ZL140OTw",
    "outputId": "f8575d02-e4f8-43c3-cf8b-54d47a11ed3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\n",
      "- processed text : know\n",
      "\n",
      "- predicted sentiment : NEGATIVE (score=38.4 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ed11f99bcf442da88b6915edcdfe84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.38427892327308655, bar_style='info', description='NEGATIVE', max=1.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"i don't know what i'm doing\", loaded_tokenizer, loaded_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "5d2f3131f0344bdfbf9f3c884a2b5289",
      "d5d9b07d27a645989bc0e004b49d274a",
      "81021b72bbf94824866b7da6167d2272"
     ]
    },
    "id": "qk03v6VhiMIX",
    "outputId": "d83673e2-42bf-4ad3-bf93-20aa92563e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\n",
      "- processed text : neutral\n",
      "\n",
      "- predicted sentiment : POSITIVE (score=76.3 %)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2f3131f0344bdfbf9f3c884a2b5289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.7627895474433899, bar_style='info', description='POSITIVE', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict(\"i am neutral\", loaded_tokenizer, loaded_clf_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11ed11f99bcf442da88b6915edcdfe84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "NEGATIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adcebac5487349ee91fbffeee7b4d942",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c31b40d5735440e5bf9bc61daf6fc264",
      "value": 0.38427892327308655
     }
    },
    "36551f8be8224c77b37e10099b3be61b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "POSITIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a2a377a20ad4ebdbda152e41f7ecd12",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4aa58ae73f34a01adeb5ec6d3a69555",
      "value": 0.9880579710006714
     }
    },
    "5a2a377a20ad4ebdbda152e41f7ecd12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d2f3131f0344bdfbf9f3c884a2b5289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "POSITIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5d9b07d27a645989bc0e004b49d274a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81021b72bbf94824866b7da6167d2272",
      "value": 0.7627895474433899
     }
    },
    "81021b72bbf94824866b7da6167d2272": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#00ff00",
      "description_width": ""
     }
    },
    "8748ebdddc2e4b91ad07ba95fa1365b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3020eb8cf6a466dba5d09dca1bd4356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#cc0000",
      "description_width": ""
     }
    },
    "adcebac5487349ee91fbffeee7b4d942": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c31b40d5735440e5bf9bc61daf6fc264": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#cc0000",
      "description_width": ""
     }
    },
    "d4aa58ae73f34a01adeb5ec6d3a69555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "#00ff00",
      "description_width": ""
     }
    },
    "d5d9b07d27a645989bc0e004b49d274a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef45692e7475432aa4a592e5c98b1b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "NEGATIVE",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8748ebdddc2e4b91ad07ba95fa1365b9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3020eb8cf6a466dba5d09dca1bd4356",
      "value": 0.011537362821400166
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
